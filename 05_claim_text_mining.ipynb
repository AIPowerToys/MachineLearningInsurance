{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6863c11",
   "metadata": {},
   "source": [
    "# Claim Text Mining\n",
    "\n",
    "Use topic modeling and text classification on synthetic adjuster narratives to prioritize investigative queues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff8d892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from faker import Faker\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Robust stopword handling: prefer NLTK, fallback to scikit-learn's built-in list\n",
    "stop_words = 'english'\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    try:\n",
    "        _ = stopwords.words('english')\n",
    "        stop_words = _\n",
    "    except LookupError:\n",
    "        try:\n",
    "            nltk.download('stopwords', quiet=True, raise_on_error=True)\n",
    "            stop_words = stopwords.words('english')\n",
    "        except Exception:\n",
    "            stop_words = 'english'\n",
    "except Exception:\n",
    "    stop_words = 'english'\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_context(\"talk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9560fa88",
   "metadata": {},
   "source": [
    "## 1. Generate synthetic claim narratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9bb845",
   "metadata": {},
   "outputs": [],
   "source": [
    "faker = Faker()\n",
    "rng = np.random.default_rng(55)\n",
    "n_samples = 400\n",
    "\n",
    "incident_types = [\"Wind\", \"Water\", \"Fire\", \"Liability\", \"Theft\"]\n",
    "resolution_codes = [\"Fast-Track\", \"Desk Review\", \"Field Inspection\", \"SIU Referral\"]\n",
    "\n",
    "narratives = []\n",
    "categories = []\n",
    "severities = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    incident = rng.choice(incident_types, p=[0.25, 0.2, 0.18, 0.2, 0.17])\n",
    "    resolution = rng.choice(resolution_codes, p=[0.4, 0.3, 0.2, 0.1])\n",
    "    severity_score = np.clip(rng.normal(loc=incident_types.index(incident) + 1, scale=0.8), 0, 5)\n",
    "    policyholder_sentence = faker.sentence(nb_words=12)\n",
    "    adjuster_observation = faker.sentence(nb_words=15)\n",
    "    remediation_step = faker.sentence(nb_words=10)\n",
    "\n",
    "    narrative = (\n",
    "        f\"Incident type: {incident}. {policyholder_sentence} {adjuster_observation} \"\n",
    "        f\"Recommended action: {remediation_step} Resolution path: {resolution}.\"\n",
    "    )\n",
    "\n",
    "    narratives.append(narrative)\n",
    "    categories.append(resolution)\n",
    "    severities.append(severity_score)\n",
    "\n",
    "text_df = pd.DataFrame(\n",
    "    {\n",
    "        \"claim_id\": np.arange(1, n_samples + 1),\n",
    "        \"incident_type\": [rng.choice(incident_types) for _ in range(n_samples)],\n",
    "        \"resolution_path\": categories,\n",
    "        \"severity_score\": severities,\n",
    "        \"adjuster_notes\": narratives,\n",
    "    }\n",
    ")\n",
    "\n",
    "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "data_path = Path(\"data/claim_texts.csv\")\n",
    "text_df.to_csv(data_path, index=False)\n",
    "print(f\"Dataset saved to {data_path.resolve()}\")\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73fbe2c",
   "metadata": {},
   "source": [
    "## 2. Topic modeling with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8f6c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/claim_texts.csv\")\n",
    "vectorizer = CountVectorizer(max_df=0.9, min_df=5, stop_words=stop_words, ngram_range=(1, 2))\n",
    "doc_term = vectorizer.fit_transform(df[\"adjuster_notes\"])\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=4, random_state=55, learning_method=\"batch\")\n",
    "topic_matrix = lda.fit_transform(doc_term)\n",
    "\n",
    "def display_topics(model, feature_names, n_top_words=10):\n",
    "    topics = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        topics.append({\"Topic\": f\"Topic {topic_idx + 1}\", \"Top Terms\": \", \".join(top_features)})\n",
    "    return pd.DataFrame(topics)\n",
    "\n",
    "display_topics(lda, vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_assignments = topic_matrix.argmax(axis=1)\n",
    "topic_summary = pd.crosstab(topic_assignments, df[\"resolution_path\"], normalize=\"index\").round(2)\n",
    "topic_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7ff73b",
   "metadata": {},
   "source": [
    "## 3. Text classification to predict resolution path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef52f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"adjuster_notes\"], df[\"resolution_path\"], test_size=0.2, random_state=55, stratify=df[\"resolution_path\"]\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 2), min_df=3)\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_test_vec = tfidf.transform(X_test)\n",
    "\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train_vec, y_train)\n",
    "y_pred = classifier.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25412199",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_coeff = zip(tfidf.get_feature_names_out(), classifier.coef_[0])\n",
    "top_tokens = sorted(feature_to_coeff, key=lambda x: abs(x[1]), reverse=True)[:15]\n",
    "token_df = pd.DataFrame(top_tokens, columns=[\"token\", \"coefficient\"])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=token_df, x=\"coefficient\", y=\"token\", palette=\"rocket\")\n",
    "plt.title(\"Influential Tokens for Fast-Track vs Other Resolutions\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
